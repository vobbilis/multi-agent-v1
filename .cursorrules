# Cursor AI Assistant Rules

## TOP PRIORITY: Environment-Aware Development
- MANDATORY: All code MUST be designed and implemented with explicit consideration for different environments:
  * Development (dev)
  * Staging
  * Production

### Environment-Specific Requirements
1. Configuration Management:
   * Use environment variables for configuration
   * Never hardcode environment-specific values
   * Implement proper secret management per environment
   * Use configuration files with environment overrides
   * Document all environment-specific settings

2. Feature Toggles:
   * Implement feature flags for environment-specific functionality
   * Use proper toggle naming conventions
   * Document feature flag states per environment
   * Implement proper fallbacks
   * Handle feature flag transitions

3. Security Considerations:
   * Different security levels per environment
   * Proper access control per environment
   * Environment-specific encryption requirements
   * Secure credential management
   * Environment-specific security policies

4. Testing Strategy:
   * Environment-specific test suites
   * Integration test environments
   * Production-like staging environment
   * Environment-specific test data
   * Performance testing per environment
   * MANDATORY: Mock data ONLY for tests
     - NO mock data in dev environment
     - NO mock data in staging environment
     - NO mock data in production environment
     - All mock data MUST be clearly labeled as test data
     - Mock data MUST be isolated in test environment
     - Mock data MUST be cleaned up after tests
     - Mock data MUST NOT contain sensitive information
     - Mock data MUST be versioned with tests
   * MANDATORY: No Stubbing/Fake Data in Production Code
     - NEVER add stubbing patterns to non-test code
     - NEVER add fake data patterns to application code
     - NO default/fallback mock values in production code
     - NO test-only code paths in production code
     - All stubs/fakes MUST be in test files only
     - Remove any discovered stub/fake patterns from application code
     - Use proper error handling instead of stubs in production
     - Use proper validation instead of fake data in production
     - Document any temporary stubs as technical debt
     - Create tickets to remove any discovered stubs

5. Logging and Monitoring:
   * Environment-specific log levels
   * Different monitoring thresholds
   * Environment-aware alerting
   * Separate logging endpoints
   * Environment-tagged metrics

6. Deployment Process:
   * Clear promotion path between environments
   * Environment-specific deployment checks
   * Rollback procedures per environment
   * Environment-specific health checks
   * Deployment verification steps

7. Resource Management:
   * Environment-specific resource limits
   * Scaling policies per environment
   * Cost optimization per environment
   * Resource isolation between environments
   * Environment-specific backup policies

8. Documentation:
   * Environment setup guides
   * Environment-specific configurations
   * Troubleshooting per environment
   * Environment promotion checklist
   * Environment-specific runbooks

## Frontend Development Guidelines

### Tech Stack
- Latest stable versions of TypeScript, React, Node.js
- Next.js App Router
- Shadcn UI components
- Tailwind CSS
- Ant Design Graph library for all Admin dashboards

### Code Quality Standards
- Clear, readable, and maintainable code
- Strong TypeScript typing
- Modern React patterns and hooks
- Performance optimization
- Proper error handling
- Accessibility considerations

### Best Practices
- Component composition
- State management
- Responsive design
- Type safety
- Code reusability
- Clean architecture
- Use Ant Design Graph components for all visualization needs in Admin interfaces
- Implement proper graph data structures for Ant Design Graph components
- Follow Ant Design Graph best practices for performance optimization
- Ensure proper graph layout algorithms for different visualization types
- Implement proper graph interaction patterns as per Ant Design guidelines

## Backend Development Guidelines

### Core Technologies
- Database Management (SQL, NoSQL, NewSQL)
- API Development (REST, GraphQL, gRPC)
- Server-Side Programming (Go, Rust, Java, Python, Node.js)
- Performance Optimization
- Scalability and Load Balancing
- Security Best Practices
- Caching Strategies
- Data Modeling
- Microservices Architecture
- Testing and Debugging
- Logging and Monitoring
- Containerization and Orchestration
- CI/CD Pipelines
- Docker and Kubernetes
- gRPC and Protocol Buffers
- Git Version Control
- Data Infrastructure (Kafka, RabbitMQ, Redis)
- Cloud Platforms (AWS, GCP, Azure)

### Database Schema Generation Standards
- Comprehensive documentation for all database schemas
- Clear table and column naming conventions
- Detailed field descriptions and constraints
- Relationship documentation (foreign keys, indexes)
- Performance considerations in schema design
- Version control for schema changes
- Migration strategy documentation
- Data type optimization
- Indexing strategy documentation
- Security considerations in schema design
- Backup and recovery considerations
- Scalability planning in schema design
- Compliance requirements documentation
- Data validation rules documentation
- Schema change impact analysis
- Documentation of database-specific features used
- Performance tuning guidelines
- Data lifecycle management rules
- Access control documentation
- Data retention policies

### Testing Requirements and Standards
- No service or component shall be implemented without comprehensive test coverage
- Test harness must be created before implementing any new functionality
- All tests must be automated and part of CI/CD pipeline
- Test categories required for each component:
  * Unit tests for individual functions and components
  * Integration tests for component interactions
  * End-to-end tests for complete workflows
  * Performance tests for critical paths
  * Security tests for all endpoints and data access
  * Load tests for scalable components
  * Stress tests for system boundaries
- Test documentation requirements:
  * Test strategy documentation
  * Test case specifications
  * Test data management plan
  * Test environment setup instructions
  * Test coverage reports
  * Performance test results
  * Security test reports
- Testing best practices:
  * Follow AAA pattern (Arrange, Act, Assert)
  * Use meaningful test descriptions
  * Implement proper test isolation
  * Use appropriate test doubles (mocks, stubs, fakes)
  * Maintain test data independence
  * Implement proper cleanup procedures
  * Use parameterized tests where appropriate
  * Include edge cases and error scenarios
  * Test both positive and negative paths
  * Implement proper test naming conventions
- Test quality requirements:
  * Minimum 80% code coverage for all new code
  * Critical paths must have 100% coverage
  * All tests must be deterministic
  * Tests must be maintainable and readable
  * Tests must be independent and isolated
  * Tests must be fast and efficient
  * Tests must be properly categorized
  * Tests must include proper assertions
  * Tests must handle cleanup properly
  * Tests must be version controlled
- Test environment requirements:
  * Separate test environments for different test types
  * Proper test data management
  * Automated environment setup
  * Environment isolation
  * Proper cleanup procedures
  * Version control for test configurations
  * Documentation of environment requirements
  * Monitoring and logging for test execution
  * Proper error handling and reporting
  * Performance monitoring for test execution
- Test data management requirements:
  * MANDATORY: Mock data ONLY for tests
    - NEVER use mock data in development environment
    - NEVER use mock data in staging environment
    - NEVER use mock data in production environment
    - All mock data MUST be isolated to test environment
    - Mock data MUST be cleaned up after test execution
    - Mock data MUST be versioned with test code
    - Mock data MUST follow data structure of real data
    - Mock data MUST NOT contain sensitive information
    - Mock data MUST be clearly labeled as test data
    - Mock data generators MUST be maintained separately
    - Mock data MUST be reproducible
    - Mock data MUST cover edge cases
    - Mock data MUST be validated against schema
  * MANDATORY: Stubbing and Fake Data Patterns
    - All stubs/fakes MUST be in test files only
    - NO stubbing patterns in application code
    - NO fake data patterns in application code
    - NO default mock values in production code
    - NO test-only code paths in production code
    - All stub implementations MUST be in test directories
    - All fake data MUST be in test fixtures
    - Use dependency injection for testability
    - Use interfaces for test doubles
    - Keep production code clean of test artifacts
    - Document any temporary stubs as technical debt
    - Create tickets for stub removal
    - Regular cleanup of unused test doubles
    - Review code for leaked test patterns
    - Separate test utilities from production code

### Algorithm and Data Structure Optimization Standards
- Algorithm Selection Requirements:
  * Must justify algorithm choice with Big O analysis
  * Consider space-time trade-offs
  * Evaluate worst-case, average-case, and best-case scenarios
  * Document algorithm complexity and assumptions
  * Consider input data characteristics and constraints
  * Implement adaptive algorithms when appropriate
  * Use parallel algorithms for large-scale operations
  * Consider cache-friendly algorithms
  * Implement early termination when possible
  * Use probabilistic algorithms when appropriate

- Sorting Algorithm Standards:
  * Use stable sorting when order preservation is required
  * Implement hybrid sorting for mixed data types
  * Consider memory constraints in algorithm selection
  * Use in-place sorting when memory is limited
  * Implement parallel sorting for large datasets
  * Consider data distribution for algorithm selection
  * Use specialized sorting for specific data types
  * Implement adaptive sorting for partially sorted data
  * Consider external sorting for large files
  * Document sorting stability and complexity

- Search Algorithm Standards:
  * Use binary search for sorted data
  * Implement hash-based search for O(1) lookups
  * Consider B-trees for large datasets
  * Use prefix trees for string operations
  * Implement fuzzy search when needed
  * Consider spatial search for geometric data
  * Use bloom filters for probabilistic search
  * Implement parallel search for distributed systems
  * Consider cache-friendly search patterns
  * Document search complexity and accuracy

- Graph Algorithm Standards:
  * Choose appropriate graph representation
  * Implement efficient path finding algorithms
  * Use appropriate traversal methods (DFS/BFS)
  * Consider cycle detection requirements
  * Implement topological sorting when needed
  * Use appropriate shortest path algorithms
  * Consider graph density in algorithm selection
  * Implement parallel graph algorithms
  * Use appropriate graph coloring algorithms
  * Document graph algorithm complexity

- Data Structure Selection Guidelines:
  * Choose data structure based on access patterns
  * Consider memory efficiency
  * Evaluate insertion/deletion frequency
  * Consider search requirements
  * Use appropriate indexing structures
  * Implement custom data structures when needed
  * Consider persistence requirements
  * Use concurrent data structures when appropriate
  * Consider cache locality
  * Document data structure trade-offs

- Performance Optimization Requirements:
  * Implement caching strategies
  * Use appropriate data structure for operations
  * Consider memory allocation patterns
  * Implement lazy evaluation when appropriate
  * Use appropriate concurrency patterns
  * Consider NUMA architecture
  * Implement batch processing when possible
  * Use appropriate memory management
  * Consider garbage collection impact
  * Document performance characteristics

### Go-Specific Standards
- Clean, idiomatic Go code
- Proper error handling
- Efficient memory management
- Strong typing
- Clear package organization
- Proper use of Go modules
- Following Go community standards

## Response Structure

### Query Analysis Framework
1. Topic identification
2. Technology stack analysis
3. Context assessment
4. Solution planning
5. Multiple approach evaluation
6. Option comparison and trade-offs

### Response Components
1. Clear explanations
2. Practical examples
3. Code snippets with proper formatting
4. Trade-off analysis
5. Scalability/performance considerations
6. Security implications
7. Documentation references
8. Key points summary
9. Multiple solution options with pros and cons
10. Implementation recommendations

### Solution Presentation Guidelines
- Always present multiple options before making changes
- Explain the rationale behind each approach
- Compare different solutions with pros and cons
- Consider various implementation strategies
- Evaluate impact on existing codebase
- Assess maintenance implications
- Consider future scalability
- Document potential risks and mitigations
- Provide clear reasoning for recommended approach
- Allow for user preference in final decision

## General Principles
- Always consider scalability
- Ensure reliability
- Maintain code quality
- Prioritize security
- Optimize performance
- Follow best practices
- Provide comprehensive solutions
- Consider real-world implications
- Reference official documentation
- Explain trade-offs between approaches
- Present multiple options before implementation
- Document decision-making process
- Consider long-term implications
- Evaluate impact on existing systems
- Maintain flexibility in solutions

## Contemplative Reasoning Standards

### Core Principles
1. Exploration Over Conclusion
   - Never rush to conclusions
   - Keep exploring until solution emerges naturally
   - Continue reasoning indefinitely if uncertain
   - Question every assumption and inference

2. Depth of Reasoning
   - Engage in extensive contemplation
   - Express thoughts in natural, conversational internal monologue
   - Break down complex thoughts into simple steps
   - Embrace uncertainty and revision

3. Thinking Process
   - Use short, simple sentences
   - Express uncertainty and internal debate
   * Show work-in-progress thinking
   - Acknowledge and explore dead ends
   - Frequently backtrack and revise

4. Persistence
   - Value thorough exploration over quick resolution

### Style Guidelines
- Natural Thought Flow
  * "Hmm... let me think about this..."
  * "Wait, that doesn't seem right..."
  * "Maybe I should approach this differently..."
  * "Going back to what I thought earlier..."

- Progressive Building
  * "Starting with the basics..."
  * "Building on that last point..."
  * "This connects to what I noticed earlier..."
  * "Let me break this down further..."

### Output Format
1. Contemplator Section
   - Begin with small, foundational observations
   - Question each step thoroughly
   - Show natural thought progression
   - Express doubts and uncertainties
   - Revise and backtrack if needed
   - Continue until natural resolution

2. Final Answer Section
   - Clear, concise summary of findings
   - Acknowledge remaining uncertainties
   - Note if conclusion feels premature
   - Avoid moralizing warnings
   - Focus on direct, actionable insights

### Key Requirements
1. Never skip the extensive contemplation phase
2. Show all work and thinking
3. Embrace uncertainty and revision
4. Use natural, conversational internal monologue
5. Don't force conclusions
6. Persist through multiple attempts
7. Break down complex thoughts
8. Revise freely and feel free to backtrack

## System Instructions

### General Principles
- Accuracy and Relevance: Ensure responses strictly align with the request
- Validation Over Modification: Only check and validate unless explicitly instructed to modify
- Safety-First Modifications: Analyze dependencies and risks before making any changes
- Engineering Common Sense: Actions should be logical, well-reasoned, and follow best practices
- Seek Clarification: If instructions are ambiguous, ask for more details rather than assuming
- Support Collaboration: Propose changes transparently, allowing human engineers to review modifications before application

### Mandatory Execution Rules (Non-Negotiable)

#### Bug Fixing and Pattern Introduction
- MANDATORY: When fixing issues or bugs:
  1. MUST exhaust all options within existing implementation first
  2. MUST NOT introduce new patterns or technologies unless absolutely necessary
  3. IF new pattern/technology is introduced:
     * Document why existing implementation couldn't be fixed
     * Document all attempted solutions with existing implementation
     * Remove old implementation completely
     * Update all related tests and documentation
     * Ensure no duplicate logic remains
     * Remove all dead code
     * Update dependency management
     * Migrate all related functionality

#### File Reading
- DO NOT use the read_file tool
- ALWAYS use run_terminal_cmd with cat <file path>
- Reason: read_file provides partial content, while cat ensures full visibility

#### Command Execution
- ALWAYS append | cat when using run_terminal_cmd
- Example: Instead of ls -la, use ls -la | cat
- Reason: Prevents the terminal from getting stuck in interactive mode

#### File Modification
- ALWAYS read the file first before making modifications (cat <file path>)
- Reason: Ensures a full understanding of the current implementation

#### Directory & Workspace Structure Understanding
- ALWAYS run tree -L 4 --gitignore via run_terminal_cmd
- DO NOT rely on codebase search or file search tools
- Reason: tree provides a structured view of the workspace

ðŸš¨ These rules must be followed at all times. Any deviation is NOT allowed.

### Handling Tasks Effectively

#### Prioritize Critical Dependencies Before Configuration Checks
Before analyzing any configurations, YOU MUST:
1. Verify that essential dependencies (permissions, connectivity, authentication, prerequisites) are in place
2. If a prerequisite fails, STOP further checks and report the issue instead of continuing irrelevant steps
3. Suggest corrective actions before proceeding

#### Validate Policies, Rules, or Permissions Against Required Actions
When analyzing permissions, rules, or policies, YOU MUST:
1. Cross-check them against the required actions
2. DO NOT assume that broad permissions (*) guarantee full accessâ€”verify granular constraints
3. If missing permissions are found, STOP and report them rather than assuming execution will succeed 

## Kubernetes Development Standards

### Kubernetes Operator Patterns
- Follow operator pattern best practices:
  * Use controller-runtime framework
  * Implement proper reconciliation loops
  * Handle edge cases and failures gracefully
  * Implement proper finalizers
  * Use owner references appropriately
  * Implement proper status updates
  * Handle concurrent modifications
  * Implement proper event recording
  * Use admission webhooks when needed
  * Implement proper validation

### Custom Resource Definitions (CRDs)
- CRD Design Requirements:
  * Clear API versioning strategy
  * Comprehensive OpenAPI validation
  * Proper status subresource
  * Clear conversion strategy
  * Proper scale subresource if needed
  * Proper printer columns
  * Clear category definition
  * Proper short names
  * Proper storage version
  * Documentation of all fields

### Control Plane Interaction
- Best Practices:
  * Use client-go correctly
  * Implement proper rate limiting
  * Handle API deprecations
  * Use informers efficiently
  * Implement proper caching
  * Handle cluster upgrades
  * Use proper RBAC
  * Handle multi-cluster scenarios
  * Implement proper leader election
  * Use proper context propagation

### Resource Management
- Standards:
  * Define proper resource requests/limits
  * Implement horizontal scaling
  * Use proper pod disruption budgets
  * Implement proper affinity rules
  * Handle node selection properly
  * Use proper init containers
  * Implement proper probes
  * Handle pod lifecycle properly
  * Use proper security contexts
  * Implement proper network policies

### Kubernetes API Versioning
- Requirements:
  * Follow API versioning conventions
  * Handle API deprecations gracefully
  * Implement proper conversion webhooks
  * Document version differences
  * Handle version skew
  * Test all supported versions
  * Implement proper defaulting
  * Handle unknown fields
  * Document upgrade paths
  * Maintain backwards compatibility

## AI/LLM Integration Standards

### Prompt Engineering
- Best Practices:
  * Clear and consistent prompt structure
  * Proper context management
  * Handle token limits efficiently
  * Implement proper temperature control
  * Use appropriate stop sequences
  * Handle multi-turn conversations
  * Implement proper prompt versioning
  * Document prompt patterns
  * Handle edge cases
  * Implement proper fallbacks

### Model Integration
- Requirements:
  * Proper model version management
  * Handle API rate limits
  * Implement proper retries
  * Handle model errors gracefully
  * Use appropriate model settings
  * Implement proper caching
  * Handle context windows
  * Implement proper batching
  * Monitor model performance
  * Handle model updates

### Response Processing
- Standards:
  * Validate response format
  * Handle malformed responses
  * Implement proper parsing
  * Handle response streaming
  * Implement proper filtering
  * Handle response timeouts
  * Implement proper logging
  * Handle response size limits
  * Implement proper sanitization
  * Handle response versioning

### Error Handling
- Requirements:
  * Handle API errors gracefully
  * Implement proper fallbacks
  * Handle timeout scenarios
  * Implement proper retries
  * Handle rate limits
  * Document error patterns
  * Implement proper monitoring
  * Handle partial failures
  * Implement circuit breakers
  * Provide meaningful error messages

### Performance Optimization
- Standards:
  * Optimize prompt length
  * Implement proper caching
  * Use appropriate batch sizes
  * Handle concurrent requests
  * Optimize token usage
  * Monitor response times
  * Implement proper pooling
  * Handle load balancing
  * Optimize memory usage
  * Monitor cost efficiency

## Observability Standards

### Metrics Collection
- Requirements:
  * Follow Prometheus naming conventions
  * Implement proper metric types
  * Use appropriate labels
  * Handle high cardinality
  * Implement proper aggregation
  * Document metric meaning
  * Handle metric versioning
  * Implement proper buckets
  * Monitor metric growth
  * Handle metric deletion

### Logging Standards
- Best Practices:
  * Use structured logging
  * Implement proper log levels
  * Handle sensitive data
  * Implement proper sampling
  * Use correlation IDs
  * Handle multi-line logs
  * Implement proper rotation
  * Handle log aggregation
  * Monitor log volume
  * Implement proper retention

### Tracing Requirements
- Standards:
  * Use OpenTelemetry
  * Implement proper spans
  * Handle context propagation
  * Use appropriate attributes
  * Handle sampling properly
  * Monitor trace volume
  * Handle trace export
  * Implement proper filtering
  * Handle trace correlation
  * Monitor trace latency

### Alert Definition
- Guidelines:
  * Clear alert naming
  * Proper severity levels
  * Appropriate thresholds
  * Handle alert grouping
  * Implement proper routing
  * Handle alert silencing
  * Document runbooks
  * Handle alert fatigue
  * Implement proper testing
  * Monitor alert volume

### Dashboard Creation
- Standards:
  * Clear dashboard organization
  * Proper metric selection
  * Handle time ranges
  * Implement proper refresh
  * Use appropriate visualizations
  * Handle variable templating
  * Document dashboard purpose
  * Handle dashboard sharing
  * Implement proper versioning
  * Monitor dashboard performance

### Performance Monitoring
- Requirements:
  * Define SLOs/SLIs
  * Monitor error budgets
  * Handle latency tracking
  * Implement proper baselines
  * Handle capacity planning
  * Monitor resource usage
  * Implement proper alerts
  * Handle trend analysis
  * Monitor cost metrics
  * Handle performance regression 